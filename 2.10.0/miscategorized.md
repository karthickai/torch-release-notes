- Replace export_for_training with export ([#162396](https://github.com/pytorch/pytorch/pull/162396))
- Redirect all use of filesystem to c10/utils/FileSystem.h ([#162914](https://github.com/pytorch/pytorch/pull/162914))
- [15/N] Use Python 3.10 typing ([#169768](https://github.com/pytorch/pytorch/pull/169768))
- [12/N] Use Python 3.10 typing ([#169355](https://github.com/pytorch/pytorch/pull/169355))
- [9/N] Use Python 3.10 typing  ([#167806](https://github.com/pytorch/pytorch/pull/167806))
- [2/N] Remove unused header inclusion ([#165831](https://github.com/pytorch/pytorch/pull/165831))
- Back out "Make PT2 compile backprop through custom op without autograd key a hard error (#166367)" ([#168142](https://github.com/pytorch/pytorch/pull/168142))
- [4/N] Use Python 3.10 typing ([#167458](https://github.com/pytorch/pytorch/pull/167458))
- [DebugMode] record triton kernels, run-to-run determinism checks ([#167028](https://github.com/pytorch/pytorch/pull/167028))
- [compile-on-one-rank] Step 1: DeviceId ([#166680](https://github.com/pytorch/pytorch/pull/166680))
- Enable PLW0127 in ruff ([#165851](https://github.com/pytorch/pytorch/pull/165851))
- Fix readibility checks in TIDY and apply them ([#164475](https://github.com/pytorch/pytorch/pull/164475))
- [6/N] Apply ruff UP035 rule ([#164438](https://github.com/pytorch/pytorch/pull/164438))
- Add pyrefly suppressions 2/n ([#164513](https://github.com/pytorch/pytorch/pull/164513))
- [1/N] Fix ruff warnings ([#164333](https://github.com/pytorch/pytorch/pull/164333))
- Fix invalid f-strings ([#164112](https://github.com/pytorch/pytorch/pull/164112))
- Support propagating custom meta field to backward graph nodes ([#164174](https://github.com/pytorch/pytorch/pull/164174))
- Return fake mode from export graph capture API ([#164730](https://github.com/pytorch/pytorch/pull/164730))
- remove more ([#164753](https://github.com/pytorch/pytorch/pull/164753))
- FakeTensorMode shouldn't cache syms when tracing ([#164718](https://github.com/pytorch/pytorch/pull/164718))
- Warn if AccumulateGrad stream does not match producer node stream ([#166136](https://github.com/pytorch/pytorch/pull/166136))
- Replace c10::call_once with static initialization ([#166381](https://github.com/pytorch/pytorch/pull/166381))
- Native matmul ([#157743](https://github.com/pytorch/pytorch/pull/157743))
- Distributed Autotuning ([#163369](https://github.com/pytorch/pytorch/pull/163369))
- Add GroupName NewType ([#167552](https://github.com/pytorch/pytorch/pull/167552))
