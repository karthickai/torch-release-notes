# Miscategorized commits

Welcome to the Pool of Miscategorized commits.
Add any commits that were miscategorized for your domain below.
Handle any commits that actually do belong to your domain and remove them from this list.

## Untopiced
- [ROCm] Add FP8 rowwise support to _scaled_grouped_mm + Submodule update ([#159075](https://github.com/pytorch/pytorch/pull/159075))
- [CPU] Support GQA for flash attention ([#157893](https://github.com/pytorch/pytorch/pull/157893))
- Improve error message for torch.binomial enforcing float inputs ([#157658](https://github.com/pytorch/pytorch/pull/157658))
- Detach tensor before clone in SGD optimiser and other code ([#159204](https://github.com/pytorch/pytorch/pull/159204))
- Feature: Implement support for `cudnn_batch_norm_out` kernel to replace the autogen approach. ([#123020](https://github.com/pytorch/pytorch/pull/123020))
- [dcp_poc] Introduce a new simple rank local checkpointer ([#156142](https://github.com/pytorch/pytorch/pull/156142))
- Create a base Checkpointer and SyncCheckpointer and add dist barrier impl and  ([#156926](https://github.com/pytorch/pytorch/pull/156926))
- [DCP] OSS Zero Overhead Checkpointing Implementation ([#156207](https://github.com/pytorch/pytorch/pull/156207))
- HF - consolidate shards of safetensors files to full tensors in finish step ([#156705](https://github.com/pytorch/pytorch/pull/156705))
- Add async checkpointing impl to experimental checkpointer and add a builder API ([#156927](https://github.com/pytorch/pytorch/pull/156927))
- Script for consolidation of sharded safetensor files ([#154743](https://github.com/pytorch/pytorch/pull/154743))
- [oss] Add version to metadata ([#155343](https://github.com/pytorch/pytorch/pull/155343))
- [HF][DCP] Upload local consolidated files to remote storage if needed ([#157371](https://github.com/pytorch/pytorch/pull/157371))
- Updates to safetensors checkpoint consolidation script to be faster ([#157936](https://github.com/pytorch/pytorch/pull/157936))
- [oss][hf][bug fix] Remove buggy consolidation logic ([#158380](https://github.com/pytorch/pytorch/pull/158380))
- DCP safetensors test fix ([#158685](https://github.com/pytorch/pytorch/pull/158685))
- [DCP] Add support for ShardedTensor to PgTransport ([#158573](https://github.com/pytorch/pytorch/pull/158573))
- Device agnostic for DCP ([#158337](https://github.com/pytorch/pytorch/pull/158337))
- [DCP] Improve error handling for process based async checkpointing ([#159374](https://github.com/pytorch/pytorch/pull/159374))
- [AOTI] Explicitly delete wait_tensor returned tensor ([#159502](https://github.com/pytorch/pytorch/pull/159502))
- [cutlass upgrade] Ignore unused-but-set-variable for AsyncMM.cu ([#159578](https://github.com/pytorch/pytorch/pull/159578))
- fix compilation on cuda < 12.3 ([#159657](https://github.com/pytorch/pytorch/pull/159657))
- [DCP][Prototype] Checkpoint replication via PGTransport (#157963) ([#159801](https://github.com/pytorch/pytorch/pull/159801))
- [AOTI] Fix memory leak from all_reduce ([#159818](https://github.com/pytorch/pytorch/pull/159818))
- HF component update to not use fsspec components ([#159405](https://github.com/pytorch/pytorch/pull/159405))
- DCP HF reader: use safe_open instead of reading the bytes ([#159406](https://github.com/pytorch/pytorch/pull/159406))
- Use only safetensors APIs in HFStorageReader ([#159681](https://github.com/pytorch/pytorch/pull/159681))
- [dcp][hf] Improve HF consolidation algorithm ([#158648](https://github.com/pytorch/pytorch/pull/158648))
- Fix requires_cuda to requires_cuda_and_triton ([#160222](https://github.com/pytorch/pytorch/pull/160222))
- Fix clang builds by adding headers ([#160252](https://github.com/pytorch/pytorch/pull/160252))
- guard cuMulticastUnbind call ([#160499](https://github.com/pytorch/pytorch/pull/160499))
- [DCP][OSS] Rank local checkpointing in DCP without collectives ([#147758](https://github.com/pytorch/pytorch/pull/147758))
- [cuda][cupy] Improve cupy device placement when device is provided with explicit index ([#158529](https://github.com/pytorch/pytorch/pull/158529))
- [dcp_poc] Fix parameter order in distributed checkpoint API to use path-first for consistency ([#160986](https://github.com/pytorch/pytorch/pull/160986))
- [dcp][hf] Fix multi-rank consolidation for no files to process case ([#160660](https://github.com/pytorch/pytorch/pull/160660))
- [DCP][HF] Add option to parallelize reads in HF Storage Reader ([#160205](https://github.com/pytorch/pytorch/pull/160205))
- [DCP][HuggingFace] Add Support for dequantization of SafeTensors checkpoints ([#160682](https://github.com/pytorch/pytorch/pull/160682))
- fix-unpin-memory-tensor-param ([#160992](https://github.com/pytorch/pytorch/pull/160992))
- bug fix for losing shape on wrapper tensor for DTensor ([#156774](https://github.com/pytorch/pytorch/pull/156774))
- add device generalization support for distributed tests ([#156796](https://github.com/pytorch/pytorch/pull/156796))
- Making batching rule for F.embedding DTensor-aware ([#162117](https://github.com/pytorch/pytorch/pull/162117))
- Remove usage of fsspec in HF consolidation script ([#159392](https://github.com/pytorch/pytorch/pull/159392))
- Add new function consolidate_safetensors_files_on_every_rank for HF consolidation ([#159393](https://github.com/pytorch/pytorch/pull/159393))
- Write full tensors out at once in HF consolidation script ([#159394](https://github.com/pytorch/pytorch/pull/159394))
- fix forced loglevel in pytorch oss code ([#158820](https://github.com/pytorch/pytorch/pull/158820))
- Add pg argument to consolidate_safetensors_files_on_every_rank ([#161421](https://github.com/pytorch/pytorch/pull/161421))
Serialization:
- Improve error message for weight-only load errors ([#159935](https://github.com/pytorch/pytorch/pull/159935))

StableABI:
- Add pad and narrow to torch/csrc/stable/ops.h ([#159328](https://github.com/pytorch/pytorch/pull/159328))
- Add getCurrentDeviceIndex to torch::stable::accelerator ([#160453](https://github.com/pytorch/pytorch/pull/160453))
- Add new_zeros dtype variant to the shim and as a stable op ([#161597](https://github.com/pytorch/pytorch/pull/161597))
- Update torch::stable::Tensor() default constructor ([#159507](https://github.com/pytorch/pytorch/pull/159507))
- Add beginnings of torch::stable::accelerator ([#159679](https://github.com/pytorch/pytorch/pull/159679))
- Port amax to stable ABI ([#160214](https://github.com/pytorch/pytorch/pull/160214))
- Add new_empty (with dtype argument only) to torch::stable ([#159508](https://github.com/pytorch/pytorch/pull/159508))
- Enable generating generic c_shim that doesn't bypass dispatcher ([#158974](https://github.com/pytorch/pytorch/pull/158974))
- Cut a version of TORCH_ERROR_CODE_CHECK in headeronly from AOTI ([#159604](https://github.com/pytorch/pytorch/pull/159604))

CUDA:
- [CUDA] Fix missing `__syncthreads` in MultiMarginLoss backward ([#158994](https://github.com/pytorch/pytorch/pull/158994))

MPS:
- [MPS] Add boilerplate sparse code support ([#157238](https://github.com/pytorch/pytorch/pull/157238))
- Add `avg_pool3d` for MPS ([#158877](https://github.com/pytorch/pytorch/pull/158877))
- [MPS] Add max_unpool1d/2d/3d ([#159789](https://github.com/pytorch/pytorch/pull/159789))
- Add `max_pool3d` for MPS ([#156467](https://github.com/pytorch/pytorch/pull/156467))
- Add `max_pool3d` backward pass for MPS ([#157498](https://github.com/pytorch/pytorch/pull/157498))
- Add `avg_pool3d` backward pass for MPS ([#159089](https://github.com/pytorch/pytorch/pull/159089))
- Enable _int_mm on Intel GPU ([#157769](https://github.com/pytorch/pytorch/pull/157769))

Python Frontend:
- Add basic torch.hash_tensor op ([#154149](https://github.com/pytorch/pytorch/pull/154149))

## not user facing
- Fix Pandas version mismatch upon reinstalling numpy ([#158584](https://github.com/pytorch/pytorch/pull/158584))
- [CUDA-13] Implement workaround for cudaErrorNotSupported ([#162412](https://github.com/pytorch/pytorch/pull/162412))
- [FP8] FP8 for SwishLayerNorm ([#157574](https://github.com/pytorch/pytorch/pull/157574))
- Add aot_export_joint_with_descriptors and aot_compile_joint_with_descriptors ([#158715](https://github.com/pytorch/pytorch/pull/158715))
- _aot_export_function: allow keeping input mutations in the graph ([#157730](https://github.com/pytorch/pytorch/pull/157730))
- Extract out prepare_aot_module_simplified for use in next PR ([#158319](https://github.com/pytorch/pytorch/pull/158319))
- Rename modules in AOTAutograd ([#158449](https://github.com/pytorch/pytorch/pull/158449))
- Track descriptors for all inputs/outputs of AOTAutograd traced graph ([#158624](https://github.com/pytorch/pytorch/pull/158624))
- Improve graph output alias with subclass error message ([#159619](https://github.com/pytorch/pytorch/pull/159619))
- Pass fw/bw compilers to aot_export_joint_with_descriptors ([#159814](https://github.com/pytorch/pytorch/pull/159814))
- Add support for param mutation under inference mode ([#159661](https://github.com/pytorch/pytorch/pull/159661))
- [PT2]: Add Static Dispatch Kernel for fmod.Scalar ([#160654](https://github.com/pytorch/pytorch/pull/160654))
- [PT2]: Add Static Dispatch Kernel for scale_gradient ([#160454](https://github.com/pytorch/pytorch/pull/160454))
- [DCP][Quantization] Fix for FP8 multiplication during dequantization ([#162202](https://github.com/pytorch/pytorch/pull/162202))
- [DCP][Quantization] Fix the issue when scale vector is in a different SafeTensors file ([#162214](https://github.com/pytorch/pytorch/pull/162214))
